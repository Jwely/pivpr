\section{Uncertainty in PIV measurements}
\label{sec:piv_uncert}
 
There are a number of factors that contribute to uncertainty in PIV 
measurements. Both bias and precision errors can be estimated by considering 
detailed information about the optical geometry of the PIV setup. Monte Carlo 
based error estimation techniques can be applied by creating artificially 
simulated images with randomly distributed particles \cite{adeyinka2005}. 
The distribution of these particles can be modeled using a Gaussian intensity  
profile by (flag, reference) as described in Equation 
\ref{eq:piv_gaussian_uncertainty}.

\begin{equation}
	I(x,y) = I_0exp \left( \frac{-(x_{img} - x_p)^2 - (y_{img} - y_p)^2}
	{\frac{1}{8}d_\tau^2} \right)
	\label{eq:piv_gaussian_uncertainty}
\end{equation}
%
Where $x_p$ and $y_p$ are the locations of the particle centroid, $d_\tau$ is 
the diameter of of the particle, and $I_0$ is particle intensity. Particle 
intensity is directly related to the intensity of the light sheet, which is 
modeled as a Gaussian distribution \cite{PIVuncertAIAA}. This assumption allows 
us 
to express particle intensity as \ref{eq:particle_intensity_gaus}

\begin{equation}
	I_0(z_p) = (q)exp\left(- \frac{z_p^2}{\frac{1}{8}\Delta Z_L^2}\right)
	\label{eq:particle_intensity_gaus}
\end{equation}
%
Where $z_p$ is the particles position within the thickness of the light sheet, 
$q$ is the particle light scattering efficiency, and $\Delta Z_L$ is the 
thickness of the light sheet.

These formula are used to generate artificial image pairs for a single camera. 
A sufficient number of particles are created with $x$, $y$ and $z$ coordinates 
to meet particle density parameters, these coordinates are then 
used to generate light intensities according to Equation 
\ref{eq:particle_intensity_gaus}, which populate the image plane of the first 
image $A$. Next, a displacement image, $B$, is generated by shifting all the 
particles in a predetermined direction in three dimensional space. It is worth 
noting that for a single camera setup, particle movements in the $z$ direction 
do not produce pixel displacements, but simply determine the intensity of the 
light reflected from the particle. The known particle displacements can then be 
compared against outputs calculated with PIV capture and processing software.

To translate this concept to stereo PIV, an additional step is required. 
Instead of directly placing particles with known coordinates onto the image 
plane of one camera, they are placed on a conceptual version of the 
interrogation plane. The coordinate transforms obtained from PIV calibration 
are used to map the displacements from the conceptual plane into the image 
plane of each camera. These coordinate transforms are unique to each camera, 
and depend upon the optical geometry of the PIV setup. Uncertainty is 
calculated using the recommended AIAA calibration procedure outlined in 
\cite{PIVuncertAIAA}. To determine the system bias, the mean difference between 
the velocity standard established by the Monte Carlo simulation and the 
velocity calculated by the PIV software are compared as follows

\begin{equation}
\overline{\Delta U} = \frac{1}{N} \left(\sum_{i=1}^N \Delta U_i \right),
\label{eq:Uerror}
\end{equation}

\begin{equation}
\overline{\Delta V} = \frac{1}{N} \left(\sum_{i=1}^N \Delta V_i \right),
\label{eq:Verror}
\end{equation}

\begin{equation}
\overline{\Delta W} = \frac{1}{N} \left(\sum_{i=1}^N \Delta W_i \right)
\label{eq:Werror}
\end{equation}
%
Which is simply the average difference between the known velocity components 
and the measured velocity components $\Delta U$, $\Delta V$, and $\Delta W$ for 
a large number of simulations. This is referred to as the bias, and the three 
bias components are denoted as

\begin{equation}
\beta_{U} = \overline{\Delta U}
\label{eq:Ubias}
\end{equation}
\begin{equation}
\beta_{V} = \overline{\Delta V}
\label{eq:Vbias}
\end{equation}
\begin{equation}
\beta_{W} = \overline{\Delta W}
\label{eq:Wbias}
\end{equation}

The measurement precision is reported as the root-mean-square of the  
standard deviation, calculated as in 
	
\begin{equation}
S_{\Delta U} = \sqrt{\frac{1}{N-1} \left(\sum_{i=1}^N (\Delta U_i - 
\overline{\Delta U})^2 \right)}
\label{eq:Usd}
\end{equation}

\begin{equation}
S_{\Delta V} = \sqrt{\frac{1}{N-1} \left(\sum_{i=1}^N (\Delta V_i - 
	\overline{\Delta V})^2 \right)}
\label{eq:Vsd}
\end{equation}

\begin{equation}
S_{\Delta W} = \sqrt{\frac{1}{N-1} \left(\sum_{i=1}^N (\Delta W_i - 
	\overline{\Delta W})^2 \right)}
\label{eq:Wsd}
\end{equation}
%
Resulting in precision calculations given by 
%	
\begin{equation}
P_{\overline{U}} = \frac{2 S_{\Delta U}}{\sqrt{N}}
\label{eq:Uprec}
\end{equation}

\begin{equation}
P_{\overline{V}} = \frac{2 S_{\Delta V}}{\sqrt{N}}
\label{eq:Vprec}
\end{equation}

\begin{equation}
P_{\overline{W}} = \frac{2 S_{\Delta W}}{\sqrt{N}}
\label{eq:Wprec}
\end{equation}

Total uncertainty for each component at the 95\% confidence level is calculated 
by combining the bias and precision via to obtain

\begin{equation}
U_{\overline{\Delta U}} = \sqrt{\beta_{U}^2 + P_{\overline{U}}^2}
\label{eq:Uuncert}
\end{equation}
\begin{equation}
U_{\overline{\Delta V}} = \sqrt{\beta_{V}^2 + P_{\overline{V}}^2}
\label{eq:Vuncert}
\end{equation}
\begin{equation}
U_{\overline{\Delta W}} = \sqrt{\beta_{W}^2 + P_{\overline{W}}^2}
\label{eq:Wuncert}
\end{equation}


For these experiments, uncertainty analysis was conducted after the 
experimental data was taken. Vortices were characterized by velocities at key 
locations that allow each vortex to be described by one of the common vortex 
models. Characterization velocities of particular interest include the maximum 
tangential velocity about the vortex core, the distance of this high tangential 
velocity region from the core, which defined the core radius, and the typical 
axial velocity distribution near the free stream velocity. Understanding the 
uncertainty of these measurements required a Monte Carlo approach from 
synthetically created particle imagery. Artificial pixel displacements were 
specified to approximate the typical displacement associated with the 
velocities of greatest interest. 

To add complexity, the time between frame captures, $dt$ was expected to have a 
significant impact on uncertainty. Since the range of velocities used in this 
study required the use of multiple values of $dt$, artificial images were 
generated for a scenario at each value of $dt$ and the associated velocities. 
With the exception of measurements at station one, the furthest upstream 
observations at $I_Z$ of 546$mm$ down stream, all tests were conducted with a 
$dt$ value of 25, or 40 $\mu s$. At station one $dt$ values of 35 were also 
used. During the experimentation period, great difficulty 
was encountered in tuning PIV parameters to achieve well resolved vector fields 
at station one. The uncertainty analysis will demonstrate that the geometry of 
viewing angles was also unfavorable at this station, and the quality of 
measurements taken this far upstream was poor, they were therefore entirely 
disregarded. 

Creation of these artificial images by Monte Carlo was performed with custom 
software written in Python. This software parses the calibration files output 
from INSIGHT software and constructs the set of equations needed for all 
coordinate transformations. In order to simulate as accurately as possible, 
artificial images were generated at the full resolution of the PIV cameras 
used, (1280 x 1024). Particles were only generated randomly at coordinates 
that were within the field of view of both cameras, to eliminate wasted 
computation time generating particles which would not aid in the production of 
a three dimensional vector. An excess of 100,000 particles were simulated for 
each image set in order to ensure particle density was sufficient to resolve a 
vector in the majority of all sectors, and to match the experimental seed 
density as closely as possible. The most accurate way to ensure the intensities 
of each particle are accurately represented is to evaluate the intensity for 
every particle every point in the full image space of 1280 x 1024 pixels, and 
then add them together. Since this produces a three dimensional space in excess 
of a five billion values for a set of $La, Lb, Ra$ and $Rb$ images, computation 
time for uncertainty images was a limiting factor. At minimum, one set of 
uncertainty images for each combination of viewing geometry and time step $dt$ 
was required. Therefore, simulated velocity values were chosen for each of the 
14 cases to approximate the velocities of greatest interest. 

Tables \ref{table:experiment_results_1} through 
\ref{table:experiment_results_7} show a summary of results from each of the 70 
tests conducted, including the maximum 
observed azimuthal velocity, the average measured axial velocity, and the low 
axial velocity at the vortex core. At the three furthest positions downstream 
where the vortex appears to have stabilized, the typical value of maximum 
tangential velocity, $\overline{t}_{max}$ in component notation, ranges from 
6.0 to 7.9 $m/s$ for each run with a $dt$ of $25 \mu s$. This tangential 
velocity could align with the $X$ or the $Y$ axis, and 
it was desirable to simulate displacements in both directions at once to limit 
the number of Monte Carlo tests to be performed, so simulated velocities
$\overline{u}_{sim}$ and $\overline{v}_{sim}$
of $4.9 m/s$ was used such that the in-plane magnitude would be equal 
to the the middle of this range. Likewise, a simulated $\overline{u}_{sim}$ and 
$\overline{v}_{sim}$  velocity of 
$3.3 m/s$ was used to create synthetic images for testing experiments with a 
$dt$ of $40 \mu s$. In the axial direction, $Z$ , mean values $19 m/s$ and $29 
m/s$ were used for the high and low velocity experiments respectively. of These 
conditions are summarized in Table \ref{table:uncertainty_sim_table}.

\input{tables/uncertainty_sim_table}

Even though many samples were taken at every vector location, the uncertainty 
in each individual measurement was of great importance for studying the 
unstable component of the velocity, and thus turbulent phenomena. Uncertainty 
in the fluctuating component were best represented by using an $N$ 
value of one in precision Equations \ref{eq:Uprec} through \ref{eq:Wprec}. 
Uncertainty in the stable component was lower, since this measurement is a 
result of averaging many measurements, and was calculated by using an $N$ value 
of 200 in the precision Equations \ref{eq:Uprec} through \ref{eq:Wprec}.


\subsection{Uncertainty Analysis Results}
The Monte Carlo analysis was performed for each station at two scenarios. 
Uncertainty in the measurements by $u, v$ and $w$ 
components are tabulated in Tables \ref{table:uncertainties_u} through 
\ref{table:uncertainties_w}. For the $u$ velocity components in the $X$ 
direction, the measurement is $\bar{u}$, bias are reported as $\beta_u$, 
precisions are reported for both single sample measurements and with 
measurements comprised of 200 averages by $P_{u^\prime}$ and $P_{\bar{u}}$ 
respectively, and total uncertainties are reported as $U_{u^\prime}$ and 
$U_{\bar{u}}$. 

\input{tables/uncertainties_u}
\input{tables/uncertainties_v}
\input{tables/uncertainties_w}

The results of the Monte Carlo analysis held some surprises. Uncertainties in 
the $X$ and $Y$ direction were comparable in some cases, while in others $Y$ 
uncertainties were half as high as those in $X$. At all velocities, poor 
precision in the individual measurements was the primary driver of total 
uncertainty, while high bias was the driver for uncertainties in the 
measurements comprised of time averages of 200 samples. Spectral analysis of 
the turbulence over the observation time is subject to the very high 
uncertainties associated with that of individual measurements. Time averaged 
velocities, and the derived Reynolds stresses are best characterized by the 
better precision offered by many samples. While 200 is nominally used as $N$, 
each grid point may have between 20 and 200 valid vectors making up the set, so 
some areas where vectors were less frequently resolved successfully may be 
characterized with greater uncertainty.

In the axial $Z$ direction, the PIV was found to have an extreme bias to 
underestimate velocities according to the Monte Carlo simulation. This bias 
starts at over 30\% at the closest station, and diminishes regularly with 
downstream position and decreasing velocity . However, experimental data shows 
axial velocity was consistently a few percent above free stream velocity 
measured in the wind tunnel by dynamic pressure as expected, as shown in Tables
\ref{table:experiment_results_1} through \ref{table:experiment_results_7}. 
Therefore, uncertainties in the $Z$ direction are overestimated by the 
technique. The stable component of Reynolds decomposition is heavily influenced 
by a high bias, but the fluctuating component is entirely sensitive to 
precision. The Reynolds stress and turbulence values which are great importance 
in this study included contributions of velocity fluctuations in the axial 
direction, which are not impacted by any bias that does exist. Experimental 
data was examined for possible misrepresentation of measurement uncertainty in 
the $X$ and $Y$ direction, but no statistically meaningful discrepancies were 
found.

\subsection{Bias from Uneven sampling}

Every grid location with at least 20 successfully resolved vectors was 
subject to a Reynolds decomposition into average and fluctuating components. 
With 200 total samples taken for each test, the results are actually made up of 
many grid points with between 20 and 200 samples. Uncertainty is related to the 
number of samples making up a measurement, but visualizing the potential 
impacts of uncertainty as it varies in two and three dimensional space is 
challenging. Furthermore, the likelihood of successfully resolving a vector is 
dependent upon aspects of the interaction between tracer particles and the 
fluid flow. A very clear interdependence between areas of high turbulence, and 
the number of successful vector calculations was observed as shown in Figures 
\ref{fig:run_55_num_contour} and \ref{fig:run_55_ctke_contour}. 

\input{figs/run_55/run_55_num_contour}
\input{figs/run_55/run_55_ctke_contour}

It was assumed that, as long as the number of samples making up any given 
measurement remains above the threshold of 20, every vector in the field is 
accurately represented. A sampling technique could be employed by 
which a random selection of 20 different values is used at every location, to 
result in a more statistically homogeneous vector field. However, 
the uncertainty in a PIV measurement also depends significantly on the 
magnitude of the velocity measured, so the benefit of such a sampling scheme is 
contestable.
